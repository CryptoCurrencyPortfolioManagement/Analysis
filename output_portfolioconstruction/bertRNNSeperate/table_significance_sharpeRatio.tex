\begin{center}
\begin{tabular}{lclc}
\toprule
\textbf{Dep. Variable:}                    &   sharpeRatio    & \textbf{  R-squared:         } &     0.736   \\
\textbf{Model:}                            &       OLS        & \textbf{  Adj. R-squared:    } &     0.722   \\
\textbf{Method:}                           &  Least Squares   & \textbf{  F-statistic:       } &     51.00   \\
\textbf{Date:}                             & Fri, 20 May 2022 & \textbf{  Prob (F-statistic):} &  1.13e-74   \\
\textbf{Time:}                             &     09:53:02     & \textbf{  Log-Likelihood:    } &   -65.993   \\
\textbf{No. Observations:}                 &         309      & \textbf{  AIC:               } &     166.0   \\
\textbf{Df Residuals:}                     &         292      & \textbf{  BIC:               } &     229.5   \\
\textbf{Df Model:}                         &          16      & \textbf{                     } &             \\
\textbf{Covariance Type:}                  &    nonrobust     & \textbf{                     } &             \\
\bottomrule
\end{tabular}
\begin{tabular}{lcccccc}
                                           & \textbf{coef} & \textbf{std err} & \textbf{t} & \textbf{P$> |$t$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{Intercept}                         &       1.0866  &        0.061     &    17.759  &         0.000        &        0.966    &        1.207     \\
\textbf{model[T.yiyanghkust/finbert-tone]} &       0.0715  &        0.037     &     1.954  &         0.052        &       -0.001    &        0.143     \\
\textbf{source[T.Twitter]}                 &      -0.8824  &        0.049     &   -18.171  &         0.000        &       -0.978    &       -0.787     \\
\textbf{dropout}                           &      -0.0366  &        0.022     &    -1.672  &         0.096        &       -0.080    &        0.006     \\
\textbf{epochs}                            &       0.0101  &        0.019     &     0.526  &         0.599        &       -0.028    &        0.048     \\
\textbf{learning\_rate}                    &      -0.1045  &        0.020     &    -5.344  &         0.000        &       -0.143    &       -0.066     \\
\textbf{linear\_layers}                    &      -0.0687  &        0.019     &    -3.699  &         0.000        &       -0.105    &       -0.032     \\
\textbf{rnn\_layers}                       &      -0.1025  &        0.026     &    -3.928  &         0.000        &       -0.154    &       -0.051     \\
\textbf{use\_attention}                    &      -0.0027  &        0.018     &    -0.153  &         0.879        &       -0.038    &        0.033     \\
\textbf{use\_price}                        &       0.0222  &        0.019     &     1.168  &         0.244        &       -0.015    &        0.060     \\
\textbf{window\_size}                      &      -0.1189  &        0.023     &    -5.162  &         0.000        &       -0.164    &       -0.074     \\
\textbf{np.power(rnn\_layers, 2)}          &       0.0022  &        0.026     &     0.084  &         0.933        &       -0.049    &        0.054     \\
\textbf{np.power(dropout, 2)}              &       0.0092  &        0.019     &     0.484  &         0.629        &       -0.028    &        0.047     \\
\textbf{np.power(learning\_rate, 2)}       &       0.0348  &        0.020     &     1.744  &         0.082        &       -0.004    &        0.074     \\
\textbf{np.power(window\_size, 2)}         &      -0.0106  &        0.024     &    -0.433  &         0.666        &       -0.059    &        0.038     \\
\textbf{np.power(linear\_layers, 2)}       &      -0.0351  &        0.023     &    -1.532  &         0.127        &       -0.080    &        0.010     \\
\textbf{np.power(epochs, 2)}               &      -0.0483  &        0.021     &    -2.257  &         0.025        &       -0.090    &       -0.006     \\
\bottomrule
\end{tabular}
\begin{tabular}{lclc}
\textbf{Omnibus:}       & 51.335 & \textbf{  Durbin-Watson:     } &    1.180  \\
\textbf{Prob(Omnibus):} &  0.000 & \textbf{  Jarque-Bera (JB):  } &   86.419  \\
\textbf{Skew:}          & -0.948 & \textbf{  Prob(JB):          } & 1.72e-19  \\
\textbf{Kurtosis:}      &  4.765 & \textbf{  Cond. No.          } &     11.2  \\
\bottomrule
\end{tabular}
%\caption{OLS Regression Results}
\end{center}

Notes: \newline
 [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.